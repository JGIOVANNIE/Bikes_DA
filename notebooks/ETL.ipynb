{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos las librerias a utilizar \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import datetime as dt\n",
    "import os \n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta de la carpeta que contiene los archivos ZIP\n",
    "ruta_carpeta = 'C:\\\\Users\\\\famil\\\\OneDrive\\\\Escritorio\\\\Proyectos\\\\BIKES\\\\Bikes_DA\\\\Datasets'\n",
    "\n",
    "# Lista todos los archivos en la carpeta\n",
    "archivos = os.listdir(ruta_carpeta)\n",
    "\n",
    "# Filtra la lista para incluir solo los archivos ZIP\n",
    "archivos_zip = [archivo for archivo in archivos if archivo.endswith('.zip')]\n",
    "\n",
    "# Crea un diccionario para almacenar los DataFrames\n",
    "dfs = {}\n",
    "\n",
    "# Abre cada archivo ZIP y lee su contenido\n",
    "for archivo_zip in archivos_zip:\n",
    "    with zipfile.ZipFile(os.path.join(ruta_carpeta, archivo_zip), 'r') as zip_ref:\n",
    "        # Abre cada archivo de texto dentro del ZIP\n",
    "        for nombre_archivo in zip_ref.namelist():\n",
    "            # Ignora los archivos que comienzan con '__MACOSX/'\n",
    "            if not nombre_archivo.startswith('__MACOSX/'):\n",
    "                with zip_ref.open(nombre_archivo) as archivo:\n",
    "                    # Lee el archivo y lo convierte a un DataFrame\n",
    "                    df = pd.read_csv(archivo)\n",
    "                    # Almacena el DataFrame en el diccionario\n",
    "                    dfs[nombre_archivo] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['202302-divvy-tripdata.csv', '202303-divvy-tripdata.csv', '202304-divvy-tripdata.csv', '202305-divvy-tripdata.csv', '202306-divvy-tripdata.csv', '202307-divvy-tripdata.csv', '202308-divvy-tripdata.csv', '202309-divvy-tripdata.csv', '202310-divvy-tripdata.csv', '202311-divvy-tripdata.csv', '202312-divvy-tripdata.csv', '202401-divvy-tripdata.csv'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de meses en orden\n",
    "meses = ['feb23', 'mar23', 'abr23', 'may23', 'jun23', 'jul23', 'ago23', 'sep23', 'oct23', 'nov23', 'dic23', 'ene24']\n",
    "\n",
    "# Crea un diccionario para almacenar los nuevos nombres\n",
    "nuevos_nombres = {}\n",
    "\n",
    "# Renombra cada DataFrame en el diccionario\n",
    "for i, (nombre, df) in enumerate(dfs.items()):\n",
    "    # Crea el nuevo nombre basado en el mes\n",
    "    nuevo_nombre =  meses[i]\n",
    "    # Almacena el DataFrame bajo el nuevo nombre\n",
    "    nuevos_nombres[nuevo_nombre] = df\n",
    "\n",
    "# Actualiza el diccionario original con los nuevos nombres\n",
    "dfs = nuevos_nombres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertir_tipos(dfs, columnas_fecha, columnas_categoricas):\n",
    "    # Itera sobre cada DataFrame en el diccionario\n",
    "    for nombre, df in dfs.items():\n",
    "        # Itera sobre cada columna de fecha en el DataFrame\n",
    "        for columna in columnas_fecha:\n",
    "            # Convierte la columna a un tipo de fecha y hora\n",
    "            df[columna] = pd.to_datetime(df[columna])\n",
    "        # Itera sobre cada columna categórica en el DataFrame\n",
    "        for columna in columnas_categoricas:\n",
    "            # Convierte la columna a un tipo categórico\n",
    "            df[columna] = df[columna].astype('category')\n",
    "\n",
    "    return dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define las columnas de fecha y categóricas\n",
    "columnas_fecha = ['started_at', 'ended_at']\n",
    "columnas_categoricas = ['ride_id', 'rideable_type', 'start_station_name', 'start_station_id', 'end_station_name', 'member_casual']\n",
    "\n",
    "# Aplica la función al diccionario de DataFrames\n",
    "dfs = convertir_tipos(dfs, columnas_fecha, columnas_categoricas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe feb23 tiene 0 filas duplicadas.\n",
      "Dataframe mar23 tiene 0 filas duplicadas.\n",
      "Dataframe abr23 tiene 0 filas duplicadas.\n",
      "Dataframe may23 tiene 0 filas duplicadas.\n",
      "Dataframe jun23 tiene 0 filas duplicadas.\n",
      "Dataframe jul23 tiene 0 filas duplicadas.\n",
      "Dataframe ago23 tiene 0 filas duplicadas.\n",
      "Dataframe sep23 tiene 0 filas duplicadas.\n",
      "Dataframe oct23 tiene 0 filas duplicadas.\n",
      "Dataframe nov23 tiene 0 filas duplicadas.\n",
      "Dataframe dic23 tiene 0 filas duplicadas.\n",
      "Dataframe ene24 tiene 0 filas duplicadas.\n"
     ]
    }
   ],
   "source": [
    "def verificar_duplicados(dfs):\n",
    "    for nombre, df in dfs.items():\n",
    "        duplicados = df.duplicated()\n",
    "        print(f\"Dataframe {nombre} tiene {duplicados.sum()} filas duplicadas.\")\n",
    "\n",
    "verificar_duplicados(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe feb23 tiene 104927 valores nulos.\n",
      "Dataframe mar23 tiene 149062 valores nulos.\n",
      "Dataframe abr23 tiene 265758 valores nulos.\n",
      "Dataframe may23 tiene 370434 valores nulos.\n",
      "Dataframe jun23 tiene 482396 valores nulos.\n",
      "Dataframe jul23 tiene 509002 valores nulos.\n",
      "Dataframe ago23 tiene 491488 valores nulos.\n",
      "Dataframe sep23 tiene 418882 valores nulos.\n",
      "Dataframe oct23 tiene 348514 valores nulos.\n",
      "Dataframe nov23 tiene 226504 valores nulos.\n",
      "Dataframe dic23 tiene 147746 valores nulos.\n",
      "Dataframe ene24 tiene 80404 valores nulos.\n"
     ]
    }
   ],
   "source": [
    "def verificar_nulos(dfs):\n",
    "    for nombre, df in dfs.items():\n",
    "        nulos = df.isnull().sum()\n",
    "        print(f\"Dataframe {nombre} tiene {nulos.sum()} valores nulos.\")\n",
    "\n",
    "verificar_nulos(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos eliminados del Dataframe feb23.\n",
      "Valores nulos eliminados del Dataframe mar23.\n",
      "Valores nulos eliminados del Dataframe abr23.\n",
      "Valores nulos eliminados del Dataframe may23.\n",
      "Valores nulos eliminados del Dataframe jun23.\n",
      "Valores nulos eliminados del Dataframe jul23.\n",
      "Valores nulos eliminados del Dataframe ago23.\n",
      "Valores nulos eliminados del Dataframe sep23.\n",
      "Valores nulos eliminados del Dataframe oct23.\n",
      "Valores nulos eliminados del Dataframe nov23.\n",
      "Valores nulos eliminados del Dataframe dic23.\n",
      "Valores nulos eliminados del Dataframe ene24.\n"
     ]
    }
   ],
   "source": [
    "def eliminar_nulos(dfs):\n",
    "    for nombre, df in dfs.items():\n",
    "        df.dropna(inplace=True)\n",
    "        print(f\"Valores nulos eliminados del Dataframe {nombre}.\")\n",
    "\n",
    "eliminar_nulos(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define una función para convertir las columnas a datetime y calcular ride_time\n",
    "def calcular_ride_time(df):    \n",
    "    # Crea la nueva columna\n",
    "    df['ride_time'] = df['ended_at'] - df['started_at']\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica la función a cada DataFrame en el diccionario\n",
    "for nombre, df in dfs.items():\n",
    "    dfs[nombre] = calcular_ride_time(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import geodesic\n",
    "\n",
    "# Define una función para calcular la distancia\n",
    "def calcular_distancia(df):\n",
    "    # Crea una nueva columna con la distancia en km\n",
    "    df['distance_km'] = df.apply(lambda row: geodesic((row['start_lat'], row['start_lng']), (row['end_lat'], row['end_lng'])).km, axis=1)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distancia calculada para feb23\n",
      "Distancia calculada para mar23\n",
      "Distancia calculada para abr23\n",
      "Distancia calculada para may23\n",
      "Distancia calculada para jun23\n",
      "Distancia calculada para jul23\n",
      "Distancia calculada para ago23\n",
      "Distancia calculada para sep23\n",
      "Distancia calculada para oct23\n",
      "Distancia calculada para nov23\n",
      "Distancia calculada para dic23\n",
      "Distancia calculada para ene24\n"
     ]
    }
   ],
   "source": [
    "# Aplica la función a cada DataFrame en el diccionario\n",
    "for nombre, df in dfs.items():\n",
    "    dfs[nombre] = calcular_distancia(df)\n",
    "    print(f\"Distancia calculada para {nombre}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformacion de ride_time en feb23 completa\n",
      "transformacion de ride_time en mar23 completa\n",
      "transformacion de ride_time en abr23 completa\n",
      "transformacion de ride_time en may23 completa\n",
      "transformacion de ride_time en jun23 completa\n",
      "transformacion de ride_time en jul23 completa\n",
      "transformacion de ride_time en ago23 completa\n",
      "transformacion de ride_time en sep23 completa\n",
      "transformacion de ride_time en oct23 completa\n",
      "transformacion de ride_time en nov23 completa\n",
      "transformacion de ride_time en dic23 completa\n",
      "transformacion de ride_time en ene24 completa\n"
     ]
    }
   ],
   "source": [
    "#  aplicamos una funcion lambda a todos los dfs para transformar la columna 'ride_time' de timedelta a tipo object para su escritura correcta en la base de datos\n",
    "for nombre, df in dfs.items():\n",
    "    df['ride_time'] = (df['ride_time'].dt.total_seconds() % 86400).apply(lambda x: dt.time(int(x // 3600), int((x % 3600) // 60), int(x % 60)))\n",
    "    print(f'transformacion de ride_time en {nombre} completa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy.exc import SQLAlchemyError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = pymysql.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  password=\"joshua\"\n",
    ")\n",
    "mycursor = mydb.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crea la base de datos \"bikes_bd\" si no existe \n",
    "mycursor.execute(\"CREATE DATABASE IF NOT EXISTS bikes_bd\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "se agrego la tabla: feb23 con exito\n",
      "se agrego la tabla: mar23 con exito\n",
      "se agrego la tabla: abr23 con exito\n",
      "se agrego la tabla: may23 con exito\n",
      "se agrego la tabla: jun23 con exito\n",
      "se agrego la tabla: jul23 con exito\n",
      "se agrego la tabla: ago23 con exito\n",
      "se agrego la tabla: sep23 con exito\n",
      "se agrego la tabla: oct23 con exito\n",
      "se agrego la tabla: nov23 con exito\n",
      "se agrego la tabla: dic23 con exito\n",
      "se agrego la tabla: ene24 con exito\n"
     ]
    }
   ],
   "source": [
    "# Crear una conexión a la base de datos\n",
    "engine = create_engine('mysql+pymysql://root:joshua@localhost/bikes_bd')\n",
    "\n",
    "# iteramos solbre el diccionario de DataFrames para crear una tabla en la base de datos por cada DF \n",
    "for nombre_tabla, df in dfs.items():\n",
    "    df.to_sql(nombre_tabla, con=engine, if_exists='replace', index=False)\n",
    "    print(f\"se agrego la tabla: {nombre_tabla} con exito\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
